{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv files in the folder Dataset\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob('Dataset/*.csv')], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>similarity</th>\n",
       "      <th>delta_mod</th>\n",
       "      <th>size</th>\n",
       "      <th>nodes_num</th>\n",
       "      <th>nb_communities</th>\n",
       "      <th>modularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0.503137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0.503137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.595846e-07</td>\n",
       "      <td>0.992093</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0.505845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.232595e-32</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0.505845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.012341e-06</td>\n",
       "      <td>0.991126</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>0.510573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25386</th>\n",
       "      <td>7.888609e-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25387</th>\n",
       "      <td>7.888609e-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25388</th>\n",
       "      <td>7.888609e-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25389</th>\n",
       "      <td>7.888609e-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25390</th>\n",
       "      <td>7.888609e-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.486395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25391 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           variance  similarity  delta_mod  size  nodes_num  nb_communities  \\\n",
       "0      0.000000e+00    1.000000   0.000000    10         69               4   \n",
       "1      0.000000e+00    1.000000   0.000000    10         69               4   \n",
       "2      6.595846e-07    0.992093   0.002707    10         69               4   \n",
       "3      1.232595e-32    1.000000   0.000000    10         69               4   \n",
       "4      2.012341e-06    0.991126   0.004729    10         69               4   \n",
       "...             ...         ...        ...   ...        ...             ...   \n",
       "25386  7.888609e-31    1.000000   0.000000   100         19               4   \n",
       "25387  7.888609e-31    1.000000   0.000000   100         19               4   \n",
       "25388  7.888609e-31    1.000000   0.000000   100         19               4   \n",
       "25389  7.888609e-31    1.000000   0.000000   100         19               4   \n",
       "25390  7.888609e-31    1.000000   0.000000   100         19               4   \n",
       "\n",
       "       modularity  \n",
       "0        0.503137  \n",
       "1        0.503137  \n",
       "2        0.505845  \n",
       "3        0.505845  \n",
       "4        0.510573  \n",
       "...           ...  \n",
       "25386    0.486395  \n",
       "25387    0.486395  \n",
       "25388    0.486395  \n",
       "25389    0.486395  \n",
       "25390    0.486395  \n",
       "\n",
       "[25391 rows x 7 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only 6 number after the comma in variance and similarity \n",
    "df['variance'] = df['variance'].apply(lambda x: round(x, 6))\n",
    "df['similarity'] = df['similarity'].apply(lambda x: round(x, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25391"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row num\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20887"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by variance similarity and nodes num and nb_communities where delta_mod is max get the index of the max delta_mod\n",
    "df_g = df.loc[df.groupby(['variance', 'similarity', 'nodes_num', 'nb_communities'])['delta_mod'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>similarity</th>\n",
       "      <th>delta_mod</th>\n",
       "      <th>size</th>\n",
       "      <th>nodes_num</th>\n",
       "      <th>nb_communities</th>\n",
       "      <th>modularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129090</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19858</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183162</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17675</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183956</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18761</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249932</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12191</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252539</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>50</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20359</th>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.884335</td>\n",
       "      <td>0.058172</td>\n",
       "      <td>95</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.164820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.875532</td>\n",
       "      <td>0.147392</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.284580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.112188</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.012465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.873288</td>\n",
       "      <td>0.094183</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.106648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6785</th>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19366 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       variance  similarity  delta_mod  size  nodes_num  nb_communities  \\\n",
       "3065   0.000000    0.129090   0.000988   100         45               2   \n",
       "19858  0.000000    0.183162   0.000988    80         45               2   \n",
       "17675  0.000000    0.183956   0.000988    70         45               2   \n",
       "18761  0.000000    0.249932   0.001953    75         45               3   \n",
       "12191  0.000000    0.252539   0.000965    50         45               3   \n",
       "...         ...         ...        ...   ...        ...             ...   \n",
       "20359  0.001185    0.884335   0.058172    95         17               8   \n",
       "5623   0.001206    0.875532   0.147392    15         19               8   \n",
       "2468   0.001574    0.919275   0.112188   100         17               9   \n",
       "2469   0.001913    0.873288   0.094183   100         17               9   \n",
       "6785   0.020661    0.818182   0.500000    20          2               2   \n",
       "\n",
       "       modularity  \n",
       "3065     0.000000  \n",
       "19858    0.000000  \n",
       "17675    0.000000  \n",
       "18761    0.000000  \n",
       "12191   -0.000988  \n",
       "...           ...  \n",
       "20359    0.164820  \n",
       "5623     0.284580  \n",
       "2468     0.012465  \n",
       "2469     0.106648  \n",
       "6785     0.000000  \n",
       "\n",
       "[19366 rows x 7 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indexs\n",
    "df_g = df_g.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>similarity</th>\n",
       "      <th>delta_mod</th>\n",
       "      <th>size</th>\n",
       "      <th>nodes_num</th>\n",
       "      <th>nb_communities</th>\n",
       "      <th>modularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.137149</td>\n",
       "      <td>0.503398</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>-0.080547</td>\n",
       "      <td>-0.065092</td>\n",
       "      <td>-0.024084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similarity</th>\n",
       "      <td>-0.137149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.532818</td>\n",
       "      <td>-0.092848</td>\n",
       "      <td>0.396171</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>-0.018315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_mod</th>\n",
       "      <td>0.503398</td>\n",
       "      <td>-0.532818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>-0.328493</td>\n",
       "      <td>-0.264351</td>\n",
       "      <td>-0.020746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>0.003714</td>\n",
       "      <td>-0.092848</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039396</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>0.012791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes_num</th>\n",
       "      <td>-0.080547</td>\n",
       "      <td>0.396171</td>\n",
       "      <td>-0.328493</td>\n",
       "      <td>0.039396</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859020</td>\n",
       "      <td>-0.284433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_communities</th>\n",
       "      <td>-0.065092</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>-0.264351</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>0.859020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.557405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modularity</th>\n",
       "      <td>-0.024084</td>\n",
       "      <td>-0.018315</td>\n",
       "      <td>-0.020746</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>-0.284433</td>\n",
       "      <td>-0.557405</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                variance  similarity  delta_mod      size  nodes_num  \\\n",
       "variance        1.000000   -0.137149   0.503398  0.003714  -0.080547   \n",
       "similarity     -0.137149    1.000000  -0.532818 -0.092848   0.396171   \n",
       "delta_mod       0.503398   -0.532818   1.000000  0.006357  -0.328493   \n",
       "size            0.003714   -0.092848   0.006357  1.000000   0.039396   \n",
       "nodes_num      -0.080547    0.396171  -0.328493  0.039396   1.000000   \n",
       "nb_communities -0.065092    0.332700  -0.264351  0.075330   0.859020   \n",
       "modularity     -0.024084   -0.018315  -0.020746  0.012791  -0.284433   \n",
       "\n",
       "                nb_communities  modularity  \n",
       "variance             -0.065092   -0.024084  \n",
       "similarity            0.332700   -0.018315  \n",
       "delta_mod            -0.264351   -0.020746  \n",
       "size                  0.075330    0.012791  \n",
       "nodes_num             0.859020   -0.284433  \n",
       "nb_communities        1.000000   -0.557405  \n",
       "modularity           -0.557405    1.000000  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get coreelation matrix of the dataframe\n",
    "df_g.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into input and output variables\n",
    "X = df_g.drop(\"size\", axis=1)\n",
    "y = df_g[\"size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>similarity</th>\n",
       "      <th>delta_mod</th>\n",
       "      <th>nodes_num</th>\n",
       "      <th>nb_communities</th>\n",
       "      <th>modularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129090</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183162</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183956</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249932</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252539</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.000988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19361</th>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.884335</td>\n",
       "      <td>0.058172</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.164820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19362</th>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.875532</td>\n",
       "      <td>0.147392</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.284580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19363</th>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.112188</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.012465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19364</th>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.873288</td>\n",
       "      <td>0.094183</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.106648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19365</th>\n",
       "      <td>0.020661</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19366 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       variance  similarity  delta_mod  nodes_num  nb_communities  modularity\n",
       "0      0.000000    0.129090   0.000988         45               2    0.000000\n",
       "1      0.000000    0.183162   0.000988         45               2    0.000000\n",
       "2      0.000000    0.183956   0.000988         45               2    0.000000\n",
       "3      0.000000    0.249932   0.001953         45               3    0.000000\n",
       "4      0.000000    0.252539   0.000965         45               3   -0.000988\n",
       "...         ...         ...        ...        ...             ...         ...\n",
       "19361  0.001185    0.884335   0.058172         17               8    0.164820\n",
       "19362  0.001206    0.875532   0.147392         19               8    0.284580\n",
       "19363  0.001574    0.919275   0.112188         17               9    0.012465\n",
       "19364  0.001913    0.873288   0.094183         17               9    0.106648\n",
       "19365  0.020661    0.818182   0.500000          2               2    0.000000\n",
       "\n",
       "[19366 rows x 6 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.29090000e-01, 9.87654321e-04, 4.50000000e+01,\n",
       "        2.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.83162000e-01, 9.87654321e-04, 4.50000000e+01,\n",
       "        2.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.83956000e-01, 9.87654321e-04, 4.50000000e+01,\n",
       "        2.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.57400000e-03, 9.19275000e-01, 1.12188366e-01, 1.70000000e+01,\n",
       "        9.00000000e+00, 1.24653740e-02],\n",
       "       [1.91300000e-03, 8.73288000e-01, 9.41828255e-02, 1.70000000e+01,\n",
       "        9.00000000e+00, 1.06648199e-01],\n",
       "       [2.06610000e-02, 8.18182000e-01, 5.00000000e-01, 2.00000000e+00,\n",
       "        2.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the input variables\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler without feature names\n",
    "import pickle\n",
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y=pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal = LinearRegression()\n",
    "modal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.0415441252611668\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using R-squared\n",
    "r_squared = modal.score(X_test, y_test)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'linearRegression_model.pkl'\n",
    "pickle.dump(modal, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NN model regression\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer=Adam(lr=0.001), metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 32)                224       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 24.2174 - mean_absolute_error: 24.2174 - val_loss: 23.9617 - val_mean_absolute_error: 23.9617\n",
      "Epoch 2/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 24.1996 - mean_absolute_error: 24.1996 - val_loss: 23.9255 - val_mean_absolute_error: 23.9255\n",
      "Epoch 3/100\n",
      "969/969 [==============================] - 7s 7ms/step - loss: 24.1659 - mean_absolute_error: 24.1659 - val_loss: 24.0354 - val_mean_absolute_error: 24.0354\n",
      "Epoch 4/100\n",
      "969/969 [==============================] - 6s 7ms/step - loss: 24.1479 - mean_absolute_error: 24.1479 - val_loss: 23.8180 - val_mean_absolute_error: 23.8180\n",
      "Epoch 5/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 24.1060 - mean_absolute_error: 24.1060 - val_loss: 23.7818 - val_mean_absolute_error: 23.7818\n",
      "Epoch 6/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 24.0291 - mean_absolute_error: 24.0291 - val_loss: 23.7423 - val_mean_absolute_error: 23.7423\n",
      "Epoch 7/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 23.8832 - mean_absolute_error: 23.8832 - val_loss: 23.5129 - val_mean_absolute_error: 23.5129\n",
      "Epoch 8/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 23.7478 - mean_absolute_error: 23.7478 - val_loss: 23.4132 - val_mean_absolute_error: 23.4132\n",
      "Epoch 9/100\n",
      "969/969 [==============================] - 6s 7ms/step - loss: 23.6561 - mean_absolute_error: 23.6561 - val_loss: 23.2557 - val_mean_absolute_error: 23.2557\n",
      "Epoch 10/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 23.5363 - mean_absolute_error: 23.5363 - val_loss: 23.1357 - val_mean_absolute_error: 23.1357\n",
      "Epoch 11/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 23.4100 - mean_absolute_error: 23.4100 - val_loss: 23.1913 - val_mean_absolute_error: 23.1913\n",
      "Epoch 12/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 23.2232 - mean_absolute_error: 23.2232 - val_loss: 23.0629 - val_mean_absolute_error: 23.0629\n",
      "Epoch 13/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 23.1665 - mean_absolute_error: 23.1665 - val_loss: 22.8610 - val_mean_absolute_error: 22.8610\n",
      "Epoch 14/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 23.0928 - mean_absolute_error: 23.0928 - val_loss: 22.7697 - val_mean_absolute_error: 22.7697\n",
      "Epoch 15/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 23.0050 - mean_absolute_error: 23.0050 - val_loss: 22.7994 - val_mean_absolute_error: 22.7994\n",
      "Epoch 16/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 22.9462 - mean_absolute_error: 22.9462 - val_loss: 22.8462 - val_mean_absolute_error: 22.8462\n",
      "Epoch 17/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 22.8783 - mean_absolute_error: 22.8783 - val_loss: 22.8966 - val_mean_absolute_error: 22.8966\n",
      "Epoch 18/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 22.8480 - mean_absolute_error: 22.8480 - val_loss: 22.6055 - val_mean_absolute_error: 22.6055\n",
      "Epoch 19/100\n",
      "969/969 [==============================] - 10s 11ms/step - loss: 22.8043 - mean_absolute_error: 22.8043 - val_loss: 22.5286 - val_mean_absolute_error: 22.5286\n",
      "Epoch 20/100\n",
      "969/969 [==============================] - 9s 10ms/step - loss: 22.7509 - mean_absolute_error: 22.7509 - val_loss: 22.8578 - val_mean_absolute_error: 22.8578\n",
      "Epoch 21/100\n",
      "969/969 [==============================] - 7s 8ms/step - loss: 22.7463 - mean_absolute_error: 22.7463 - val_loss: 22.4841 - val_mean_absolute_error: 22.4841\n",
      "Epoch 22/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 22.6986 - mean_absolute_error: 22.6986 - val_loss: 22.8271 - val_mean_absolute_error: 22.8271\n",
      "Epoch 23/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 22.6533 - mean_absolute_error: 22.6533 - val_loss: 22.5249 - val_mean_absolute_error: 22.5249\n",
      "Epoch 24/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 22.6646 - mean_absolute_error: 22.6646 - val_loss: 22.4241 - val_mean_absolute_error: 22.4241\n",
      "Epoch 25/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.6479 - mean_absolute_error: 22.6479 - val_loss: 22.4076 - val_mean_absolute_error: 22.4076\n",
      "Epoch 26/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.6400 - mean_absolute_error: 22.6400 - val_loss: 22.3826 - val_mean_absolute_error: 22.3826\n",
      "Epoch 27/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.5818 - mean_absolute_error: 22.5818 - val_loss: 22.4185 - val_mean_absolute_error: 22.4185\n",
      "Epoch 28/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 22.5567 - mean_absolute_error: 22.5567 - val_loss: 22.3901 - val_mean_absolute_error: 22.3901\n",
      "Epoch 29/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.5274 - mean_absolute_error: 22.5274 - val_loss: 22.3424 - val_mean_absolute_error: 22.3424\n",
      "Epoch 30/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 22.5064 - mean_absolute_error: 22.5064 - val_loss: 22.5458 - val_mean_absolute_error: 22.5458\n",
      "Epoch 31/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.4747 - mean_absolute_error: 22.4747 - val_loss: 22.6782 - val_mean_absolute_error: 22.6782\n",
      "Epoch 32/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 22.5048 - mean_absolute_error: 22.5048 - val_loss: 22.2597 - val_mean_absolute_error: 22.2597\n",
      "Epoch 33/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 22.4072 - mean_absolute_error: 22.4072 - val_loss: 22.1804 - val_mean_absolute_error: 22.1804\n",
      "Epoch 34/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 22.4173 - mean_absolute_error: 22.4173 - val_loss: 22.1512 - val_mean_absolute_error: 22.1512\n",
      "Epoch 35/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.3909 - mean_absolute_error: 22.3909 - val_loss: 22.2303 - val_mean_absolute_error: 22.2303\n",
      "Epoch 36/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 22.3621 - mean_absolute_error: 22.3621 - val_loss: 22.1178 - val_mean_absolute_error: 22.1178\n",
      "Epoch 37/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.2832 - mean_absolute_error: 22.2832 - val_loss: 22.0792 - val_mean_absolute_error: 22.0792\n",
      "Epoch 38/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 22.2523 - mean_absolute_error: 22.2523 - val_loss: 22.0632 - val_mean_absolute_error: 22.0632\n",
      "Epoch 39/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 22.1994 - mean_absolute_error: 22.1994 - val_loss: 21.9033 - val_mean_absolute_error: 21.9033\n",
      "Epoch 40/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 22.1695 - mean_absolute_error: 22.1695 - val_loss: 21.8880 - val_mean_absolute_error: 21.8880\n",
      "Epoch 41/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 22.1387 - mean_absolute_error: 22.1387 - val_loss: 22.7684 - val_mean_absolute_error: 22.7684\n",
      "Epoch 42/100\n",
      "969/969 [==============================] - 4s 5ms/step - loss: 22.1222 - mean_absolute_error: 22.1222 - val_loss: 22.0783 - val_mean_absolute_error: 22.0783\n",
      "Epoch 43/100\n",
      "969/969 [==============================] - 4s 4ms/step - loss: 22.1051 - mean_absolute_error: 22.1051 - val_loss: 23.1971 - val_mean_absolute_error: 23.1971\n",
      "Epoch 44/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 22.0200 - mean_absolute_error: 22.0200 - val_loss: 21.8586 - val_mean_absolute_error: 21.8586\n",
      "Epoch 45/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 22.0354 - mean_absolute_error: 22.0354 - val_loss: 21.6665 - val_mean_absolute_error: 21.6665\n",
      "Epoch 46/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 21.9911 - mean_absolute_error: 21.9911 - val_loss: 21.6115 - val_mean_absolute_error: 21.6115\n",
      "Epoch 47/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 21.9391 - mean_absolute_error: 21.9391 - val_loss: 21.6733 - val_mean_absolute_error: 21.6733\n",
      "Epoch 48/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 21.8712 - mean_absolute_error: 21.8712 - val_loss: 21.5113 - val_mean_absolute_error: 21.5113\n",
      "Epoch 49/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 21.8182 - mean_absolute_error: 21.8182 - val_loss: 21.5011 - val_mean_absolute_error: 21.5011\n",
      "Epoch 50/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 21.7916 - mean_absolute_error: 21.7916 - val_loss: 21.4651 - val_mean_absolute_error: 21.4651\n",
      "Epoch 51/100\n",
      "969/969 [==============================] - 5s 6ms/step - loss: 21.7693 - mean_absolute_error: 21.7693 - val_loss: 21.5139 - val_mean_absolute_error: 21.5139\n",
      "Epoch 52/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 21.7907 - mean_absolute_error: 21.7907 - val_loss: 22.1720 - val_mean_absolute_error: 22.1720\n",
      "Epoch 53/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 21.6899 - mean_absolute_error: 21.6899 - val_loss: 21.2938 - val_mean_absolute_error: 21.2938\n",
      "Epoch 54/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 21.6855 - mean_absolute_error: 21.6855 - val_loss: 21.2389 - val_mean_absolute_error: 21.2389\n",
      "Epoch 55/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 21.6528 - mean_absolute_error: 21.6528 - val_loss: 21.7778 - val_mean_absolute_error: 21.7778\n",
      "Epoch 56/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 21.5408 - mean_absolute_error: 21.5408 - val_loss: 21.1605 - val_mean_absolute_error: 21.1605\n",
      "Epoch 57/100\n",
      "969/969 [==============================] - 6s 7ms/step - loss: 21.5302 - mean_absolute_error: 21.5302 - val_loss: 21.1902 - val_mean_absolute_error: 21.1902\n",
      "Epoch 58/100\n",
      "969/969 [==============================] - 8s 9ms/step - loss: 21.5287 - mean_absolute_error: 21.5287 - val_loss: 23.8970 - val_mean_absolute_error: 23.8970\n",
      "Epoch 59/100\n",
      "969/969 [==============================] - 7s 7ms/step - loss: 21.4746 - mean_absolute_error: 21.4746 - val_loss: 21.1668 - val_mean_absolute_error: 21.1668\n",
      "Epoch 60/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 21.4850 - mean_absolute_error: 21.4850 - val_loss: 21.0701 - val_mean_absolute_error: 21.0701\n",
      "Epoch 61/100\n",
      "969/969 [==============================] - 10s 11ms/step - loss: 21.4032 - mean_absolute_error: 21.4032 - val_loss: 20.9794 - val_mean_absolute_error: 20.9794\n",
      "Epoch 62/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 21.3241 - mean_absolute_error: 21.3241 - val_loss: 20.9223 - val_mean_absolute_error: 20.9223\n",
      "Epoch 63/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 21.3294 - mean_absolute_error: 21.3294 - val_loss: 20.8040 - val_mean_absolute_error: 20.8040\n",
      "Epoch 64/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 21.1881 - mean_absolute_error: 21.1881 - val_loss: 21.0100 - val_mean_absolute_error: 21.0100\n",
      "Epoch 65/100\n",
      "969/969 [==============================] - 9s 10ms/step - loss: 21.1602 - mean_absolute_error: 21.1602 - val_loss: 20.5774 - val_mean_absolute_error: 20.5774\n",
      "Epoch 66/100\n",
      "969/969 [==============================] - 8s 9ms/step - loss: 21.1853 - mean_absolute_error: 21.1853 - val_loss: 20.8985 - val_mean_absolute_error: 20.8985\n",
      "Epoch 67/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 21.1128 - mean_absolute_error: 21.1128 - val_loss: 20.7688 - val_mean_absolute_error: 20.7688\n",
      "Epoch 68/100\n",
      "969/969 [==============================] - 8s 9ms/step - loss: 21.3121 - mean_absolute_error: 21.3121 - val_loss: 21.1523 - val_mean_absolute_error: 21.1523\n",
      "Epoch 69/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 21.1517 - mean_absolute_error: 21.1517 - val_loss: 21.0690 - val_mean_absolute_error: 21.0690\n",
      "Epoch 70/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 21.0818 - mean_absolute_error: 21.0818 - val_loss: 21.0602 - val_mean_absolute_error: 21.0602\n",
      "Epoch 71/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 21.0126 - mean_absolute_error: 21.0126 - val_loss: 20.7513 - val_mean_absolute_error: 20.7513\n",
      "Epoch 72/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 21.0612 - mean_absolute_error: 21.0612 - val_loss: 20.4302 - val_mean_absolute_error: 20.4302\n",
      "Epoch 73/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 21.0756 - mean_absolute_error: 21.0756 - val_loss: 20.3314 - val_mean_absolute_error: 20.3314\n",
      "Epoch 74/100\n",
      "969/969 [==============================] - 9s 10ms/step - loss: 20.9212 - mean_absolute_error: 20.9212 - val_loss: 20.7708 - val_mean_absolute_error: 20.7708\n",
      "Epoch 75/100\n",
      "969/969 [==============================] - 9s 10ms/step - loss: 20.9931 - mean_absolute_error: 20.9931 - val_loss: 20.1962 - val_mean_absolute_error: 20.1962\n",
      "Epoch 76/100\n",
      "969/969 [==============================] - 10s 10ms/step - loss: 20.9126 - mean_absolute_error: 20.9126 - val_loss: 20.2541 - val_mean_absolute_error: 20.2541\n",
      "Epoch 77/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.9158 - mean_absolute_error: 20.9158 - val_loss: 20.2985 - val_mean_absolute_error: 20.2985\n",
      "Epoch 78/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.8556 - mean_absolute_error: 20.8556 - val_loss: 20.7336 - val_mean_absolute_error: 20.7336\n",
      "Epoch 79/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 20.8864 - mean_absolute_error: 20.8864 - val_loss: 20.1432 - val_mean_absolute_error: 20.1432\n",
      "Epoch 80/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.8392 - mean_absolute_error: 20.8392 - val_loss: 20.2561 - val_mean_absolute_error: 20.2561\n",
      "Epoch 81/100\n",
      "969/969 [==============================] - 7s 7ms/step - loss: 20.7946 - mean_absolute_error: 20.7946 - val_loss: 20.2353 - val_mean_absolute_error: 20.2353\n",
      "Epoch 82/100\n",
      "969/969 [==============================] - 5s 5ms/step - loss: 20.8441 - mean_absolute_error: 20.8441 - val_loss: 20.2385 - val_mean_absolute_error: 20.2385\n",
      "Epoch 83/100\n",
      "969/969 [==============================] - 6s 6ms/step - loss: 20.7313 - mean_absolute_error: 20.7313 - val_loss: 21.3073 - val_mean_absolute_error: 21.3073\n",
      "Epoch 84/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.7811 - mean_absolute_error: 20.7811 - val_loss: 20.8603 - val_mean_absolute_error: 20.8603\n",
      "Epoch 85/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 20.7250 - mean_absolute_error: 20.7250 - val_loss: 20.1907 - val_mean_absolute_error: 20.1907\n",
      "Epoch 86/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 20.7569 - mean_absolute_error: 20.7569 - val_loss: 19.9481 - val_mean_absolute_error: 19.9481\n",
      "Epoch 87/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 20.6703 - mean_absolute_error: 20.6703 - val_loss: 20.3482 - val_mean_absolute_error: 20.3482\n",
      "Epoch 88/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 20.7377 - mean_absolute_error: 20.7377 - val_loss: 20.2748 - val_mean_absolute_error: 20.2748\n",
      "Epoch 89/100\n",
      "969/969 [==============================] - 9s 10ms/step - loss: 20.5985 - mean_absolute_error: 20.5985 - val_loss: 20.0771 - val_mean_absolute_error: 20.0771\n",
      "Epoch 90/100\n",
      "969/969 [==============================] - 9s 9ms/step - loss: 20.6299 - mean_absolute_error: 20.6299 - val_loss: 20.5406 - val_mean_absolute_error: 20.5406\n",
      "Epoch 91/100\n",
      "969/969 [==============================] - 9s 10ms/step - loss: 20.7440 - mean_absolute_error: 20.7440 - val_loss: 20.0580 - val_mean_absolute_error: 20.0580\n",
      "Epoch 92/100\n",
      "969/969 [==============================] - 6s 7ms/step - loss: 20.5795 - mean_absolute_error: 20.5795 - val_loss: 19.9776 - val_mean_absolute_error: 19.9776\n",
      "Epoch 93/100\n",
      "969/969 [==============================] - 7s 7ms/step - loss: 20.6285 - mean_absolute_error: 20.6285 - val_loss: 19.9672 - val_mean_absolute_error: 19.9672\n",
      "Epoch 94/100\n",
      "969/969 [==============================] - 9s 10ms/step - loss: 20.6394 - mean_absolute_error: 20.6394 - val_loss: 20.0441 - val_mean_absolute_error: 20.0441\n",
      "Epoch 95/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.6510 - mean_absolute_error: 20.6510 - val_loss: 20.5674 - val_mean_absolute_error: 20.5674\n",
      "Epoch 96/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.6394 - mean_absolute_error: 20.6394 - val_loss: 20.0311 - val_mean_absolute_error: 20.0311\n",
      "Epoch 97/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.5665 - mean_absolute_error: 20.5665 - val_loss: 20.0937 - val_mean_absolute_error: 20.0937\n",
      "Epoch 98/100\n",
      "969/969 [==============================] - 8s 9ms/step - loss: 20.5406 - mean_absolute_error: 20.5406 - val_loss: 19.9095 - val_mean_absolute_error: 19.9095\n",
      "Epoch 99/100\n",
      "969/969 [==============================] - 7s 7ms/step - loss: 20.5856 - mean_absolute_error: 20.5856 - val_loss: 22.3666 - val_mean_absolute_error: 22.3666\n",
      "Epoch 100/100\n",
      "969/969 [==============================] - 8s 8ms/step - loss: 20.6365 - mean_absolute_error: 20.6365 - val_loss: 20.3017 - val_mean_absolute_error: 20.3017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f93772c580>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(X_train, y_train,validation_data=(X_test,y_test), epochs=100, batch_size=16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 1s 3ms/step - loss: 20.3017 - mean_absolute_error: 20.3017\n",
      "R-squared: [20.30165672302246, 20.30165672302246]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using R-squared\n",
    "r_squared = model.evaluate(X_test, y_test)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.drop(\"delta_mod\", axis=1)\n",
    "y2 = df[\"delta_mod\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modal2 = LinearRegression()\n",
    "modal2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0.00044632 0.00491586 0.00242556 ... 0.00035621 0.00329236 0.00887766]\n",
      "Actual values: [0.00053022 0.00308277 0.00064959 ... 0.00052938 0.00216146 0.01211706]\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set and print the results\n",
    "y_pred2 = modal2.predict(X_test2)\n",
    "print(\"Predictions:\", y_pred2)\n",
    "print(\"Actual values:\", y_test2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.6889139034298117\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model using R-squared\n",
    "r_squared = modal2.score(X_test2, y_test2)\n",
    "print(\"R-squared:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
